{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity as cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('id+abstract.pkl', 'rb') as f:\n",
    "    df = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 20s, sys: 1.64 s, total: 2min 22s\n",
      "Wall time: 2min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_features=30000, stop_words='english')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer_ngram1 = TfidfVectorizer(stop_words='english', ngram_range=(1, 1), max_features=30000)\n",
    "%time tfidf_vectorizer_ngram1.fit(df.abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_vectorizer_ngram2 = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), max_features=30000)\n",
    "# %time tfidf_vectorizer_ngram2.fit(df.abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_v = tfidf_vectorizer_ngram1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 29s, sys: 1.01 s, total: 2min 30s\n",
      "Wall time: 2min 30s\n"
     ]
    }
   ],
   "source": [
    "%time X_tfidf = tfidf_v.transform(df.abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_thesis = \"\"\"\n",
    "Wildfires are a growing problem in the US and worldwide – in the last decade we\n",
    "witnessed some of the costliest, most destructive, and deadliest wildland fires on record.\n",
    "The consistent growth in the number of incidents, affected area, and suppression costs\n",
    "suggests that the issue might become even worse in the future. Solutions include early fire\n",
    "detection and preventative scanning of the vast wildlands. This thesis proposes a\n",
    "vision-based multimodal fire detection system that is deployed on an Unmanned Aerial\n",
    "Vehicle (UAV, drone) and can be used for early detection of new wildfires, and\n",
    "surveillance of existing ones. The Fire Perception Box multimodal perception hardware is\n",
    "designed and deployed onboard a custom built UAV. Visual spectrum (RGB) and infrared\n",
    "(IR) classification algorithms along with a fusion strategy are proposed and deployed to\n",
    "the UAV system. Overall, the system is capable of fully onboard real-time visual\n",
    "processing and produces spatial results which can later be utilized for realtime wildfire\n",
    "maps — a technology that is very much needed in fire management. The effectiveness of\n",
    "the system is shown via quantitative evaluation on the proposed Aerial Fire Dataset, as\n",
    "well as external datasets. Furthermore, the performance of the system is evaluated on\n",
    "never-seen data from a real-world 80-acre wildfire.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_abstact = \"\"\"\n",
    "Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers.\n",
    "The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(abstr):\n",
    "    x = tfidf_v.transform([abstr])\n",
    "    sims = cos_sim(X_tfidf, x)\n",
    "    sims = np.squeeze(sims)\n",
    "    most_sim_idx = sims.argsort()\n",
    "    return df.iloc[most_sim_idx[:10]].abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tfidf_v.transform([my_thesis])\n",
    "sims = cos_sim(X_tfidf, x)\n",
    "sims = np.squeeze(sims)\n",
    "most_sim_idx = sims.argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('X_tfidf.pkl', 'wb') as f:\n",
    "    pickle.dump(X_tfidf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1325672,  837142, 1312419, ...,  303361,  303362, 1789906])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_sim_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  The challenge of wildfire management and detection is recently gaining\\nincreased attention due to the increased severity and frequency of wildfires\\nworldwide. Popular fire detection techniques such as satellite imaging and\\nremote camera-based sensing suffer from late detection and low reliability\\nwhile early wildfire detection is a key to prevent massive fires. In this\\npaper, we propose a novel wildfire detection solution based on unmanned aerial\\nvehicles assisted Internet of things (UAV-IoT) networks. The main objective is\\nto (1) study the performance and reliability of the UAV-IoT networks for\\nwildfire detection and (2) present a guideline to optimize the UAV-IoT network\\nto improve fire detection probability under limited budgets. We focus on\\noptimizing the IoT devices' density and number of UAVs covering the forest area\\nsuch that a lower bound of the wildfires detection probability is maximized\\nwithin a limited time and budget. At any time after the fire ignition, the IoT\\ndevices within a limited distance from the fire can detect it. These IoT\\ndevices can then report their measurements only when the UAV is nearby.\\nDiscrete-time Markov chain (DTMC) analysis is utilized to compute the fire\\ndetection probability at discrete time. Before declaring fire detection, a\\nvalidation state is designed to account for IoT devices' practical limitations\\nsuch as miss-detection and false alarm probabilities. Numerical results suggest\\nthat given enough system budget, the UAV-IoT based fire detection can offer a\\nfaster and more reliable wildfire detection solution than the state of the art\\nsatellite imaging techniques.\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1325672].abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.37 s, sys: 176 ms, total: 1.54 s\n",
      "Wall time: 1.54 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1789906      The Ginzburg Landau theory for d_{x^2-y^2}-w...\n",
       "776722       The static properties of the fundamental mod...\n",
       "356930       We study ultracold Rydberg-dressed Bose gase...\n",
       "776724       Inspired by recent work of Carlson, Friedlan...\n",
       "776725       The transient Be/X-ray binary A0538-66 shows...\n",
       "1635971      Dyonic black holes with string-loop correcti...\n",
       "1635973      The emitted power of the radiation from a ch...\n",
       "1635974      We prove that there do not exist multisolito...\n",
       "776731       Ivory's Lemma is a geometrical statement in ...\n",
       "1635975      Using the results of previous investigations...\n",
       "Name: abstract, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time inference(resnet_abstact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1789906      The Ginzburg Landau theory for d_{x^2-y^2}-w...\n",
       "303362       Let $H(\\mathbb{B})$ denote the space of all ...\n",
       "303361       We study the discreteness for non-elementary...\n",
       "303360       In this article, we assume that a cold charg...\n",
       "799639       We prove that intermediate extensions of per...\n",
       "1671642      We study the general gaugings of N=2 Maxwell...\n",
       "1671643      We present what we believe is the minimal th...\n",
       "1671644      We investigate the instanton effects of non-...\n",
       "1438950      BVRI light curves are presented for 27 Type ...\n",
       "1671639      Vacuum spherically symmetric Einstein gravit...\n",
       "Name: abstract, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference(my_thesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_sim_idx = sims.argsort()[::-1] # reverse \n",
    "# if we also want to reject the paper itself, then it'd be most_sim_idx[-2::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1325672,  837142, 1312419, ...,  303361,  303362, 1789906])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_sim_idx"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
